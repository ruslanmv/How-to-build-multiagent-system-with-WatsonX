{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [],
   "source": [
    "#from crewai import Crew, Task, Agent\n",
    "from langchain_ibm import WatsonxLLM\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import DecodingMethods\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Load API key and project ID from environment variables\n",
    "watsonx_api_key = os.getenv(\"WATSONX_API_KEY\")\n",
    "project_id = os.getenv(\"PROJECT_ID\")\n",
    "url = os.getenv(\"WATSONX_URL\")\n",
    "\n",
    "# WatsonxLLM parameters\n",
    "parameters = {\n",
    "    GenParams.DECODING_METHOD: DecodingMethods.SAMPLE.value,\n",
    "    GenParams.MAX_NEW_TOKENS: 100,\n",
    "    GenParams.MIN_NEW_TOKENS: 50,\n",
    "    GenParams.TEMPERATURE: 0.7,\n",
    "    GenParams.TOP_K: 50,\n",
    "    GenParams.TOP_P: 1\n",
    "}\n",
    "\n",
    "if not watsonx_api_key or not project_id:\n",
    "    raise ValueError(\"Please set the WATSONX_API_KEY and PROJECT_ID in your .env file.\")\n",
    "\n",
    "# Define LLM models using WatsonxLLM\n",
    "llm = WatsonxLLM(\n",
    "    model_id=\"meta-llama/llama-3-1-70b-instruct\",  \n",
    "    url=url,\n",
    "    apikey=watsonx_api_key,\n",
    "    project_id=project_id,\n",
    "    params=parameters\n",
    ")\n",
    "\n",
    "# Tool Initialization for the Researcher\n",
    "tavily_tool = TavilySearchResults(max_results=5)  \n",
    "\n",
    "# Router Agent definition\n",
    "def router_decision(user_query):\n",
    "    \"\"\"Router agent that selects either 'Researcher' or 'Creator' based on the user input.\"\"\"\n",
    "    if \"price\" in user_query or \"news\" in user_query:\n",
    "        return \"Researcher\"\n",
    "    else:\n",
    "        return \"Creator\"\n",
    "\n",
    "router = Agent(\n",
    "    llm=llm,\n",
    "    role=\"Router\",\n",
    "    goal=\"Decide whether to use the Researcher or Creator agent based on the user query.\",\n",
    "    function=router_decision,\n",
    "    backstory=\"You are a router that directs queries to the appropriate agent.\"\n",
    ")\n",
    "\n",
    "# Researcher Agent\n",
    "researcher = Agent(\n",
    "    llm=llm,\n",
    "    role=\"Researcher\",\n",
    "    goal=\"Fetch the latest information available on the internet based on the user query.\",\n",
    "    backstory=\"You are an AI researcher skilled in retrieving the latest information.\",\n",
    "    tools=[tavily_tool]  \n",
    ")\n",
    "\n",
    "# Creator Agent\n",
    "creator = Agent(\n",
    "    llm=llm,\n",
    "    role=\"Creator\",\n",
    "    goal=\"Generate informative and accurate knowledge-based responses to user queries.\",\n",
    "    backstory=\"You are an AI assistant specializing in generating knowledge-based answers.\"\n",
    ")\n",
    "\n",
    "# Define tasks for the agents\n",
    "task_router = Task(\n",
    "    description=\"Route the user query to either the Researcher or Creator agent.\",\n",
    "    expected_output=\"Either 'Researcher' or 'Creator'\",\n",
    "    agent=router\n",
    ")\n",
    "\n",
    "task_researcher = Task(\n",
    "    description=\"Fetch search results based on the user query.\",\n",
    "    expected_output=\"A summary of the search results.\",\n",
    "    agent=researcher\n",
    ")\n",
    "\n",
    "task_creator = Task(\n",
    "    description=\"Generate a response to the user query based on general knowledge.\",\n",
    "    expected_output=\"An informative response.\",\n",
    "    agent=creator\n",
    ")\n",
    "\n",
    "# Assemble the crew with the agents and tasks\n",
    "crew = Crew(\n",
    "    agents=[router, researcher, creator],\n",
    "    tasks=[task_router, task_researcher, task_creator],\n",
    "    verbose=True,\n",
    "    output_log_file=\"crew_log.txt\", \n",
    "    share_crew=False\n",
    ")\n",
    "\n",
    "# Execute the workflow \n",
    "def crew_workflow(user_query):\n",
    "    print(\"\\n==== Starting Crew Workflow ====\\n\")\n",
    "    \n",
    "    # Step 1: Router Agent determines which agent to use\n",
    "    print(f\"[Router] Evaluating the query: '{user_query}'\")\n",
    "    selected_agent = router_decision(user_query)\n",
    "    print(f\"[Router] Selected Agent: {selected_agent}\\n\")\n",
    "    \n",
    "    # Step 2: Based on the selected agent, either Researcher or Creator is invoked\n",
    "    if selected_agent == \"Researcher\":\n",
    "        print(f\"[Researcher] Processing query: '{user_query}'\")\n",
    "        search_result = tavily_tool.invoke(user_query)  \n",
    "        print(f\"[Researcher] Result: {search_result}\\n\")\n",
    "    elif selected_agent == \"Creator\":\n",
    "        creator_prompt = f\"Please provide an informative response for: '{user_query}'\"\n",
    "        result = llm.invoke(creator_prompt) \n",
    "        print(f\"[Creator] Result: {result}\\n\")\n",
    "\n",
    "# Example usage\n",
    "crew_workflow(\"Fetch the bitcoin price over the past 5 days.\") \n",
    "crew_workflow(\"Explain what Bitcoin is.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
